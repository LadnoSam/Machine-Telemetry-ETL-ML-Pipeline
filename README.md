# ğŸš€ Machine Telemetry ETL & ML Pipeline  
### Airflow â€¢ PostgreSQL â€¢ Python â€¢ Machine Learning Models

This project implements a fully automated **ETL + ML pipeline** orchestrated by Apache Airflow, using PostgreSQL as the database and Python for feature engineering, ingestion, and machine learning utilities.

The pipeline performs:

- Database initialization (tables, indexes)
- CSV ingestion into PostgreSQL (high-performance batch insert)
- Automatic ML model feature-name fixes
- Scaler validation using real feature samples
- Daily or manual Airflow execution

---

## ğŸ“ Project Structure

```
airflow/
â”‚ docker-compose.yaml
â”‚ .env
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ db_pipeline_dag.py
â”‚
â”œâ”€â”€ project/
â”‚   â”œâ”€â”€ db.py
â”‚   â”œâ”€â”€ database_and_model_tools.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ machine_data_cleaned.csv
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ best_regressor_v18.pkl
â”‚   â”‚   â”œâ”€â”€ regression_scaler_v18.pkl
â”‚   â”‚   â”œâ”€â”€ classifier_fault_idle_v18.pkl
â”‚   â”‚   â”œâ”€â”€ classifier_fault_idle_scaler_v18.pkl
â”‚   â”‚   â”œâ”€â”€ classifier_active_maint_v18.pkl
â”‚   â”‚   â”œâ”€â”€ classifier_active_maint_scaler_v18.pkl
â”‚   â”‚   â”œâ”€â”€ best_anomaly_detector_v18.pkl
â”‚   â”‚   â””â”€â”€ anomaly_scaler_v18.pkl
â”‚   â””â”€â”€ __init__.py
â”‚
â””â”€â”€ logs/
```

---

## ğŸ³ Running Airflow with Docker Compose

### 1ï¸âƒ£ Download Airflow Compose template

```bash
curl -LfO "https://airflow.apache.org/docs/apache-airflow/stable/docker-compose.yaml"
```

### 2ï¸âƒ£ Start the entire Airflow stack

```bash
docker compose up -d
```

Airflow Web UI:  
ğŸ‘‰ http://localhost:8080  
Login: `airflow`  
Password: `airflow`

---

## âš™ï¸ Environment Variables (.env)

Place this file inside:

```
project/.env
```

```env
DB_HOST=postgres
DB_NAME=airflow
DB_USER=airflow
DB_PASSWORD=airflow
DB_PORT=5432
```

---

## ğŸ“Š Airflow DAG â€” ETL + ML Pipeline

DAG file: `dags/db_pipeline_dag.py`  
Pipeline ID: **machine_db_pipeline**

### âœ” Task 1 â€” init_database
- Creates required tables  
- Creates database indexes  
- Loads CSV telemetry dataset into PostgreSQL  

### âœ” Task 2 â€” fix_model_features
- Normalizes feature names  
- Updates stored models & scalers  
- Ensures compatibility  

### âœ” Task 3 â€” test_scaler_output
- Loads regression scaler  
- Evaluates transformation  

---

## ğŸ“… Schedule (Daily Execution)

Set daily execution:

```python
schedule_interval="@daily"
```

---

## ğŸ—„ Inspecting PostgreSQL Database

```bash
docker compose exec postgres psql -U airflow -d airflow
```

Useful commands:

```
\dt
\d telemetry
SELECT COUNT(*) FROM telemetry;
```

---

## ğŸ‰ Summary

This repo provides:

âœ” End-to-end ETL pipeline  
âœ” Clean PostgreSQL schema  
âœ” Automated ML model fixes  
âœ” Scaler validation  
âœ” Airflow orchestration  
âœ” Full Docker environment  

